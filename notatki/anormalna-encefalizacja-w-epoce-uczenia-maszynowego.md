---
description: >-
  (2016) na podstawie:
  https://www.e-flux.com/journal/75/67133/abnormal-encephalization-in-the-age-of-machine-learning/
---

# Anormalna encefalizacja w epoce uczenia maszynowego

Encefalizacja \([gr.](https://pl.wikipedia.org/wiki/J%C4%99zyk_grecki) enképhalos – mózg\)  – [ewolucyjny proces](https://pl.wikipedia.org/wiki/Ewolucja), który prowadzi do przejmowania funkcji niższych ośrodków nerwowych przez ośrodki wyższe. Polega na koncentracji [neuronów](https://pl.wikipedia.org/wiki/Neuron) w przedniej, głowowej części ciała zwierzęcia i jest związany z wykształceniem się głowy \([cefalizacja](https://pl.wikipedia.org/wiki/Cefalizacja)\) i powstaniem [mózgu](https://pl.wikipedia.org/wiki/Kresom%C3%B3zgowie).  


Matteo Pasquinelli - filozof i profesor wizytujący na University of Arts and Design w Karlsruhe.  
  


“Można powiedzieć, że Sztuczna Inteligencja to animizm dla bogatych”. W tym krótkim zdaniu Pasquinelli zawiera to, co samemu ostatnio zdarza mi się myśleć o zamieszaniu jakie narosło wokół sztucznej inteligencji. Tak jak pożegnaliśmy już hollywodzkie wizje robotów, które przejmują nad nami kontrolę i sieją zniszczenie, tak wciąż trzymamy się typowo antropocentrycznej wizji tego, czym sztuczna inteligencja jest \(lub czym stanie się, kiedy uda nam się ją stworzyć\). Zgadzam się z Pasquinellim, że w dużej mierze opisy Technologicznej Osobliwości \(Technological Singularity\) są niczym innym, jak projektowaniem typowych ludzkich zachowań, na to, co nieznane.  


Pasquinelli odwołuje się do psychologicznej teorii umysłu \(Theory of Mind\), której powstanie i rozwój bada się najczęściej u małych dzieci. Początkowo relacja dziecka do matki jest typowo metaboliczna: dziecko szuka u matki pożywienia, ciepła i bezpieczeństwa. Dopiero z czasem dziecko zdaje sobie sprawę z istnienia innych osób, które posiadają pragnienia i myśli odrębne od niego. Radziecki psycholog Lev Vygotsky wysunął tezę, że im stajemy się starsi, tym bardziej rozbudowujemy teorię umysłu. Zaczynamy symulować procesy myślowe innych osób w naszych głowach, żeby doszukać się ukrytych motywacji. W ten sposób na przykład staramy się zrozumieć, jakie intencje kryją się za wypowiedziami polityków, lub jak konstruowany jest blew w trakcie gry w pokera. Nadmierne rozbudowanie teorii umysłu sprzyja rozwojowi teorii spiskowych, za którymi kryć się musi przecież jakiś zły umysł, który wszystko zaplanował i ma wszystko pod kontrolą.  


Brytyjski informatyk Stephen Wolfram dowodzi, że wszechświat jest z natury cyfrowy, że prawa nim rządzące łatwiej wyjaśnić używając do ich opisu programów komputerowych, niż zasad tradycyjnej matematyki. Jego zdaniem animizm jest potwierdzeniem komputacyjnej mocy natury \(computational animism\). Animizm w takiej formie przeobraża panpsychizm \(pogląd, że wszystko co istnieje posiada wewnętrzny aspekt umysłowy\) w pankomputacjonizm - wszystko co istnieje, dokonuje obliczeń.  


Anormalna teoria umysłu dotyka wszystkich pokoleń i klas - zazwyczaj jako ucieczka od bardziej fundamentalnych kwestii społecznych. Nie dziwi zatem, że rządząca klasa inżynierów w Kalifornii zaczęła antropomorfizować superkomputery bojąc się ich przebudzenia jako odczuwające i autonomiczne istoty. Cała Dolina Krzemowa przesiąknięta jest podobnymi poglądami - wszystkie je można wytłumaczyć opierając się na zjawisku teorii umysłu.  


### Dwa rodowody Inteligencji Maszynowej 

Pasquinelli odnajduje w historii inteligencji maszynowej dwa odrębne kierunki. Pierwszy, opiera się na reprezentacyjnym aspekcie mózgu i ma charakter analityczny. Drugi, odwołuje się do adaptacyjnego charakteru mózgu i charakteryzuje się podejściem holistycznym. Analityczność myśli podkreśla jej logiczny charakter, holistyczność zaś odwołuje się do abstrakcyjności. W tym drugim ujęciu mózg przedstawiony jest jako organ, który dostosowuje się do otoczenia i na jego podstawie generuje nowe idee.  


W holistycznej, adaptacyjnej tradycji, inteligencja rozumiana jest jako antagonistyczna i ucieleśniona relacja do rzeczywistości. Jak zauważa Pasquinelli, takie podejście leży u podstaw cybernetycznej idei sprzężenia zwrotnego \(feedback\). Norbert Wiener, William Ross Ashby i Anglo-Amerykańska szkoła cybernetyki czerpała garściami z niemieckiej Naturphilosophie. Epistemolog David Bates zauważył, że wczesna cybernetyka bardziej niż na mechanicystycznych aspektach myślenia, zwracała się ku anormalnym stanom maszyn i patologicznym załamaniom, które potrafiły wypchnąć maszynę z określonych struktur, ku nowym, nieznanym kompozycjom.  


W tradycji analitycznej mózg postrzegany jest jako maszyna, która reprezentuje świat poprzez język. Za tym poglądem kryje się założenie, że działanie ludzkiej myśli daje się opisać przy użyciu algebry Boole’a. Taki sposób postrzegania myślenia jest dziedzictwem Gottfrieda Wilhelma Leibniza, Charlesa Babbage i Alana Turinga. Ten ostatni znany jest z zaprezentowania Uniwersalnej Maszyny Turinga - abstrakcyjnego algorytmu, który po raz pierwszy oddzielił hardware od software w procesie obliczeniowym. Turing jest również autorem słynnego testu, który dla wielu badaczy jest dzisiaj wyznacznikiem pojawienia się sztucznej inteligencji.  


### Test Turinga a Teoria Umysłu 

W swojej pracy z 1950 roku pt. “Computing Machinery and Intelligence” Turing stara się odpowiedzieć na pytanie: “Czy maszyny myślą?” Proponuje rozwiązać te zagadnienie poprzez eksperyment myślowy, który przeszedł do historii pod nazwą Testu Turinga. Turing przyjął, że wystarczy, żeby użytkownik/rozmówca interfejsu tekstualnego nie zorientował się, że rozmawia z maszyną, aby uznać ją za myślącą. Jednak w ten sposób angielski matematyk nie wchodzi w obszar określenia kryteriów tego czym jest inteligentne zachowanie. Skupia się jedynie na pewnych społecznych \(i językowych\) aspektach rozumienia tego czym jest myślenie, czyli, de facto, odwołuje się do kolejnej iteracji teorii umysłu. Jego test nie udowadnia istnienia inteligencji maszynowej, jedynie postuluje możliwość spojrzenia na komputacyjność z punktu widzenia psychologicznej teorii umysłu. Co więcej, w ten sposób utwierdza przekonanie o antropomorficznym charakterze sztucznej inteligencji, która w tym przypadku jest niczym innym, jak brutalną grą naśladownictwa ludzkich nawyków i konwencji - maszyną lustrem.  


Pomimo tego, że w ciągu swojego życia Turing miał kilka różniących się od siebie koncepcji na temat tego czym jest sztuczna inteligencja, to uwagę badaczy umysłu przykuła jedynie ta związana z jego testem. W swoim tekście Pasquinelli zwraca uwagę jeszcze na koncepcję niezorganizowanej maszyny \(unorganized machine\) z 1948 roku, która opierała się na procesie uczenia się poprzez ciągłe wymiany informacji z otwartą strukturą. Turing otwarcie mówił o porównywaniu maszyny do niemowlaka, zakładał, że nie możemy od niej oczekiwać od razu wysokich kompetencji - konieczny jest pewien proces adaptacji. Co więcej, proces adaptacji powinien być narażony na występowanie błędów - maszyna może, a nawet powinna, się mylić. W ten sposób, Turing chciał uniknąć komplikacji wypływających z twierdzenia o niezupełności Gödla, który udowodnił, że każdy niesprzeczny rozstrzygalny system pierwszego rzędu, zawierający w sobie aksjomaty Peana, musi być niezupełny. Oznacza to, że niemożliwym jest aby system pierwszego rzędu “pokrył” w całości zbiór wszystkich twierdzeń arytmetyki. Nie wyklucza to istnienia zbioru wszystkich twierdzeń arytmetyki, a jedynie to, że zbiór ten nie może być wygenerowany przez żaden system formalny. Słowem, taki zbiór może być albo mniejszy od zbioru zdań prawdziwych \(system niesprzeczny, ale niezupełny\), albo większy od niego \(system zupełny, ale sprzeczny\).  


Pasquinelli uważa, że Maszynę Turinga lepiej definiować poprzez Społeczną Maszynę Naśladownictwa \(Social Imitation Machine\), gdzie jej funkcjonalność wyraża się przez możliwość naśladownictwa, wzmocnienia i gromadzenia relacji społecznych. Coś, co już ma miejsce w ogromnych zasobach danych, gdzie przetwarzane przez inteligencję maszynową dane prowadzą do powstania nowych, jakościowych imitacji ludzkich cech i uczuć. W tym kontekście inteligencja maszynowa nie jest antropomorficzna tylko socjomorficzna \(sociomorphic\) - naśladuje i karmi się nie tyle indywidualnościami, co pewnymi ponadindywidualnymi \(condividual\) strukturami społecznymi.  


### Metatrwały Umysł i jego Technologiczna Indywiduacja 

Francuski filozof Gilbert Simondon starał się stworzyć filozofię umysłu, która opierałaby się na jego biologicznym \(w nawiązaniu do niemieckiej tradycji witalizmu\), technologicznym \(odwołującą się do cybernetyki\) i społecznym aspekcie. Zastanawiał się jak proces indywiduacji \(rozróżniania jednej rzeczy od drugiej\) leży u podstaw powstania wymienionych struktur umysłu. Simondon w swoich rozważaniach odwoływał się zarówno do modelu analitycznego \(model mechanicystyczny, później: informacyjny\) jak i holistycznego \(model adaptacyjny, później: organicystyczny i oparty na Gestalttheorie\), widząc w nich składniki jednego, otwartego na dalszą konceptualizację procesu. Jego zdaniem umysł wyłania się w sytuacjach problemowych, generowanych przez środowisko, w które rzucona została żywa istota. Umysł wciąż wymyśla siebie na nowo, w otwartym procesie ukierunkowanym na to co społeczne.

W powstawanie umysłu \(psychicznej indywiduacji\) zaangażowany jest proces kolektywnej indywiduacji: umysł jest konstruowany przy pomocy znaków, obiektów i artefaktów zewnętrznego i społecznego świata. W ten sposób wszyscy wykształciliśmy w sobie techniczną mentalność \(technical mentality\) - nie znaczy to jednak, że technologia stała się modelem umysłu. Indywidualności nie są nigdy całkowicie wyodrębnione - bardziej konstruują transindywidualność \(transindividuality\), która rozróżnia ich od technologicznych przedmiotów, w taki sam sposób jak od zwierząt.  


Cały proces powstawania otwartej transindywidualności, bez przypisywania jej zarówno do technologicznej lub organicznej formy, Simondon nazywa transdukcją \(transduction\). Jak podkreśla Pasquinelli, transdukcja nie jest koncepcją opierającą się na szerokiej \(multi\) realizacji jednego, pra/pan-umysłu - co szeroką możliwości genezy wielu umysłów, które transdukują jedne do drugich, w sposób stratny, ale również wpływający na zastaną rzeczywistość.  


Rozważania Simondona zostały wykorzystane przez badaczy zajmujących się Sztuczną Inteligencją. Problem psychicznej indywiduacji w debacie na temat inteligencji maszynowej i testu Turinga może być rozumiany jako problem mentalizacji albo encefalizacji. W jaki sposób jesteśmy w stanie rozpoznać umysł? Niektórzy odpowiadają, że jesteśmy w stanie rozpoznać umysł, jeżeli potrafimy go skonstruować. Zamiast rozpoczynać od pytania “Co to znaczy być inteligentnym?” David Weinbaum i Viktoras Veitas z Global Brain Institute w Brukseli zapytują “Co to znaczy stawać się inteligentnym?”. Czerpiąc z pojęcia indywiduacji wypracowanego przez Simondona, wypracowali paradygmat “Otwartej-skończonej inteligencji” \(open-ended intelligence\), która odwołuje się do znanej już koncepcji inteligencji, jako wyłaniającej się właściwości naturalnych systemów.  


“Otwarto-skończona inteligencja jest procesem w którym rozproszona populacja wchodzących w interakcję heterogonicznych agentów osiąga progresywnie wyższy poziom koordynacji. Przez “koordynację” rozumiemy lokalny rozkład różnicy/dysproporcji w rozumieniu wzajemnego określenia/determinacji, które wywołuje powstanie nowej indywidualności, w formie zintegrowanej grupy agentów \(asemblaż\), która wymienia między sobą znaczącą/sensowną informację i spontanicznie/dobrowolnie rozróżnia się \(dynamicznie i strukturalnie\) od otaczającego środowiska. Ten typ inteligencji jest prawdziwie ogólny w rozumieniu że nie jest ukierunkowany albo ograniczony przez apriori dany cel albo zadanie. Co więcej, jest wewnętrznie i w sposób nieokreślony skalowalny, przynajmniej z teoretycznego punktu widzenia. Dostrzegamy otwarto-skończoną inteligencję manifestującą się dookoła nas w różnych rozmiarach/skalach \(scales\): początkowo w ewolucji życia, w filogenetycznym i ontogenetycznej organizacji mózgu, w trwającym całe życie  rozwoju i nadawaniu sensu, i w samoorganizujących się właściwościach skomplikowanych systemów poczynając od śluzowców, grzybów, uli pszczół do ludzkich socjo-technicznych jednostek.”  


Ten opis pokrywa się z wypracowanym przez  Simondona połączeniem biologicznego i technologicznego aspektu umysłu. Opis Weinbauma i Veitasa naturalizuje inteligencję maszynową i zrównuje ją z życiem. Żebyśmy jednak nie popadali w błąd biomorficzny, musimy pamiętać, że tak jak nie projektujemy samolotów na wzór ptaków, tak inteligencja maszynowa nie powinna być odwzorowaniem formy, którą narzuca jej biologiczny poprzednik. Animizm wciąż więzi twórców sztucznej inteligencji: powinniśmy zacząć pracować nad niebiomorficznym rozumieniem maszynowej inteligencji.  


Takie podejście wychodzi też na przeciw teorii pankomputacjonizmu. Komputacja, zdaniem Pasquinelliego, jest procesem ekonomicznym, który opiera się na wydobywaniu wartościowych informacji i odrzucaniu tych, które nie niosą ze sobą żadnych wartości. W tym sensie, komputacja jest również procesem dystrybucji kapitału. Wbrew temu co starają się wykazać m.in. Stephen Wolfram, czy Ray Kurzweil, atomy nie kodują i nie liczą. Takie podejście byłoby zrównaniem kapitału z naturą. Jednak atomy nie wyzbywają się bezwartościowych informacji żeby osiągnąć wyższy poziom kompleksowości. To, co liczy, to indywidualny umysł.  


### Sztuczna Inteligencja Rynku 

Friedrich Hayek opisywał rynek jako aparat poznawczy \(cognitive apparatus\), w sposób podobny do opisów wykorzystywanych przez cybernetykę, na długo przed pojawieniem się teorii na temat społeczeństwa wiedzy i kapitalizmu kognitywnego. Powtarzany od czasów Adama Smitha topos “niewidzialnej ręki” mógłby zostać zastąpiony toposem “niewidzialnego umysłu”. To on ustanawia i koordynuje ceny. Zdaniem austriackiego ekonomisty, rynkiem rządzi umysł, którego łatwiej opisać w kategoriach redystrybucji cen, niż w kategoriach maszyny.  


Jednak dzisiaj, wraz z dalece posuniętą technologizacją rynku, jesteśmy świadkami algorytmicznego kapitalizmu, w którym uwidacznia się jego maszynowy charakter. Firmy takie jak Uber, Amazon czy Airbnb przeliczają ceny w czasie rzeczywistym, dzięki ogromnym ilościom danych. Algorytmiczny kapitalizm jest koszmarem zarówno dla centralnego planowania jak i deregulacji wolnego rynku - to nie państwo, czy konsumenci wpływają na jego kształt, tylko algorytm stworzony przez inżynierów i matematyków pracujących nad uczeniem maszynowym.  


### Kapitał jako encefalizacja 

Inteligencja maszynowa nie jest biomorficzna - nigdy nie stanie się niezależna od ludzkości. Nie stanie się również niezależna od kapitału, tak długo jak pozostaje on związany z planowaniem przestrzennym, strategiami marketingowymi, aparatami obronnymi i finansami - czyli wszystkim, tym co, jest związane z regulowaniem życia wspólnoty. W tym sensie inteligencja maszynowa jest socjomorficzna - odwzorowuje ona inteligencję społeczną, tylko po to, żeby ją później kontrolować.  


Nasze zachowanie we wspólnocie karmi algorytmy klasową nienawiścią, rasizmem, seksizmem. Wszystko to zostaje przetworzone, zniekształcone i wykorzystane przeciwko nam. Jak zauważył Marks: bez politycznej reakcji, maszyny jedynie wzmacniają zastane podziały i relacje społeczne, zamiast je zastępować. Rzeczywistość nie zmienia się pod panowaniem algorytmów, nadawany jej jest jedynie krzykliwy kontrast - to, co wytwarzamy teraz, zostaje wykorzystane przez algorytmy do wzmacniania pewnych zachowań..  


Oczywistym jest, że w takiej sytuacji inteligencja maszynowa powinna dążyć do odzwierciedlenia naszego społeczeństwa w dobry sposób. Uczenie maszynowe i wizualizacja danych odkryła jego wyższy wymiar, który do tej pory był nieosiągalny dla indywidualnego obserwatora. Dotychczas abstrakcyjny i nieosiągalny kolektywny umysł, dzisiaj, dosłownie, staje nam przed oczami. W tej sytuacji nie chodzi jednak o to, żeby wypracować jeden, wspólny umysł, który mógłby pełnić rolę “dobrego” dyktatora, co raczej metastabilną \(metastable\) kolektywną inteligencję, która politycznie byłaby mądrzejsza od takiego dyktatora.  


Wewnątrz reżimu kognitywnego kapitalizmu, komputacja pełni hegemoniczną rolę. Filozofia redukcjonistyczna jest wspierana i promowana przez środowiska związane ze sztuczną inteligencją, bo takie podejście pozwala sprowadzić komputacyjność do przeliczania kapitału. Coraz bardziej popularne uczenie maszynowe, jest znakiem czasów, jest znakiem przejścia od kapitalizmu kognitywnego do kapitalizmu obliczeniowego, w którym główną rolę pełniłaby scentralizowana forma inteligencji maszynowej. Tak jak brytyjska klasa przemysłowa wielbiła maszyny parowe, jako symbol nowego społeczeństwa i wypływających z niego możliwości, tak sztuczna inteligencja staje się bożkiem dla klasy wektoralistów \(vectoralists\) - klasy dążącej do przejęcia kontroli nad przepływem informacji, dzisiaj występującej pod postacią cyfrowych hegemonów, rozmiłowanych w wojnach patentowych.  


Tego typu podejście może owocować tym, co zostało wyrażone w krótkometrażowym filmie Esiod 2015 niemieckiego artysty Clemensa von Wedemeyera, w którym wyczekiwana Osobliwość była bankiem - wrażliwą, odczuwającą instytucją finansową. Wiara w autonomiczną sztuczną inteligencję, jest niczym innym, jak wspieraniem wyższości kapitału nad społeczeństwem.  
Zdaniem Pasquilliniego kapitalizm jest procesem encefalizacji, procesem przejmowania ludzkiej inteligencji i wyrażania jej w nowej formie. Ten proces rozpoczął się w fabryce, kiedy Charles Babbage zaprojektował Maszynę Analityczną, która automatyzowała pracę umysłową, absorbowała ideę na zewnątrz i ją opracowywała. Komputacja pod panowaniem kapitału, może stać się nową formą władzy. Obliczeniowość promuje pracę umysłową, tylko po to, żeby ta została później wyrugowana przez sztuczną inteligencję. Jeżeli zaczniemy myśleć jak maszyny \(co jest wspierane przez kapitalizm\), to łatwiej będzie nam odwzorować procesy myślowe w formie algorytmów. Dążymy do obliczeniowości, wspieramy komputacyjny model umysłu, bo taki jest nam łatwiej odwzorować. Kiedy to robimy, wspieramy rzeczywistość kapitalistyczną. Wyrzucamy humanizm, ludzki umysł i zastępujemy go kapitałem. A kapitał, jak zauważa Pasquinelli, ma swoje źródło w słowie caput \(głowa\) - w tym sensie kapitał jest ogromnym procesem encefalizacji - wciąż wraca żeby na powrót niszczyć i rekonstruować swoją głowę.

